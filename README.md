kdown
# ‚õΩ Corridor Service Analytics: Real-Time Multi-Service Pipeline
[![Spark](https://img.shields.io/badge/Apache_Spark-3.5.0-orange?style=flat&logo=apachespark)](https://spark.apache.org/)
[![Kafka](https://img.shields.io/badge/Apache_Kafka-7.5.0-black?style=flat&logo=apachekafka)](https://kafka.apache.org/)
[![MongoDB](https://img.shields.io/badge/MongoDB-6.0-green?style=flat&logo=mongodb)](https://www.mongodb.com/)
[![Docker](https://img.shields.io/badge/Docker-Orchestrated-blue?style=flat&logo=docker)](https://www.docker.com/)

## üìù Pr√©sentation
Ce projet d√©ploie une **Architecture Lambda** compl√®te pour le monitoring de l'exp√©rience client au sein des stations-service au Mali. Le syst√®me analyse la performance de l'ensemble des p√¥les d'activit√© :
- ‚õΩ **Carburant** (Gestion de l'attente et qualit√© du service)
- üõí **Boutique & Restauration** (Disponibilit√© et accueil)
- üßº **Lavage Auto** (Satisfaction technique)
- ‚ô®Ô∏è **Service Gaz** (Fluidit√© de l'approvisionnement)

L'objectif est de transformer des flux d'avis h√©t√©rog√®nes en insights actionnables pour optimiser les op√©rations en temps r√©el.



## üèóÔ∏è Architecture Technique
L'infrastructure repose sur un environnement multi-conteneurs Docker simulant un √©cosyst√®me Big Data industriel :

- **Ingestion (Edge)** : Producteur Python haute fr√©quence simulant les transactions et avis clients.
- **Broker (Kafka)** : D√©couplage des flux et persistance temporaire pour une r√©silience maximale.
- **Speed Layer (Spark Streaming)** : Analyse de sentiment en temps r√©el (Satisfait/Insatisfait) via PySpark.
- **Serving Layer (NoSQL)** : **MongoDB** pour le stockage des indicateurs chauds et **Streamlit** pour la visualisation.
- **Batch Layer (Data Lake)** : Archivage immuable en JSON converti au format **Parquet** pour des analyses historiques optimis√©es.

## üöÄ D√©ploiement

### 1. Lancement de l'infrastructure (Docker)
```bash
docker-compose up -d --build
2. D√©marrage du Pipeline de Traitement
Bash
docker exec -it spark-master-1 spark-submit \
  --master spark://spark-master-1:7077,spark-master-2:7077 \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.mongodb.spark:mongo-spark-connector_2.12:10.3.0 \
  /opt/spark/apps/sentiment_analysis.py
3. Compactage vers le Data Lake (Batch Layer)
Bash
docker exec -it spark-master-1 spark-submit /opt/spark/apps/compact_to_parquet.py
üìä Points d'acc√®s Monitoring
Dashboard Streamlit : http://localhost:8501 (Visualisation des KPIs)

Spark Master UI : http://localhost:8080 (Gestion du cluster)

Mongo Express : http://localhost:8082 (Exploration des donn√©es)

üí° D√©fis Techniques Relev√©s
Haute Disponibilit√© : Configuration d'un cluster Spark avec 2 Masters (via Zookeeper) et 5 Workers.

Sch√©ma √âvolutif : Utilisation du format JSON pour capturer la diversit√© des avis sans contrainte de sch√©ma rigide.

Optimisation Storage : Impl√©mentation du format Parquet (format colonne) r√©duisant l'espace disque et acc√©l√©rant les requ√™tes analytiques.


---

